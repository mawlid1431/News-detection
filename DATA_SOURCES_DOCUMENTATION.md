# ðŸ“° **Trustify AI - News Sources & Data Integration Documentation**

### _Comprehensive Guide to 100+ News Sources and Multi-Source Verification_

---

## ðŸ“‹ **Overview**

Trustify AI integrates with **100+ trusted news sources** worldwide to provide comprehensive fact-checking and news verification. Our multi-source approach ensures accurate, unbiased verification by cross-referencing claims against diverse, credible news outlets and official sources.

---

## ðŸŒ **News Sources Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        NEWS SOURCES INTEGRATION ARCHITECTURE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         API-BASED SOURCES                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚    GNews API    â”‚  â”‚   NewsAPI.org   â”‚  â”‚    Currents API         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚   (Real-time)   â”‚  â”‚  (Comprehensive)â”‚  â”‚   (International)       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ 60,000+ sites â”‚  â”‚ â€¢ 80,000+ sites â”‚  â”‚ â€¢ 50,000+ sources       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Real-time     â”‚  â”‚ â€¢ Historical    â”‚  â”‚ â€¢ Multi-language        â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Multi-lang    â”‚  â”‚ â€¢ Full articles â”‚  â”‚ â€¢ Breaking news         â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Guardian API   â”‚  â”‚  NewsData.io    â”‚  â”‚    MediaStack API       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (Quality)      â”‚  â”‚   (Global)      â”‚  â”‚    (Professional)       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                         â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ High quality  â”‚  â”‚ â€¢ 50+ countries â”‚  â”‚ â€¢ Real-time feeds       â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Editorial     â”‚  â”‚ â€¢ Categorized   â”‚  â”‚ â€¢ Professional sources â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Fact-checked  â”‚  â”‚ â€¢ Live updates  â”‚  â”‚ â€¢ Verified content      â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                           â”‚
â”‚                             Parallel Processing                                â”‚
â”‚                                    â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                         RSS FEED SOURCES                               â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                  INTERNATIONAL SOURCES                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Reuters   â”‚ â”‚  BBC News   â”‚ â”‚    Associated Press     â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ (9.5/10)    â”‚ â”‚  (9.2/10)   â”‚ â”‚      (9.4/10)           â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚    CNN      â”‚ â”‚ Al Jazeera  â”‚ â”‚    Deutsche Welle       â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (8.5/10)   â”‚ â”‚  (8.7/10)   â”‚ â”‚      (8.8/10)           â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                    MALAYSIAN SOURCES                           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Bernama   â”‚ â”‚  The Star   â”‚ â”‚  New Straits Times      â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (9.0/10)   â”‚ â”‚  (8.8/10)   â”‚ â”‚      (8.6/10)           â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Malay Mail  â”‚ â”‚ Free Mal.   â”‚ â”‚    The Malaysian        â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (8.4/10)   â”‚ â”‚  (8.2/10)   â”‚ â”‚      (8.3/10)           â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                    SPECIALIZED SOURCES                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Health WHO  â”‚ â”‚ Sci. Nature â”‚ â”‚    Gov. Official        â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚  (9.8/10)   â”‚ â”‚  (9.6/10)   â”‚ â”‚      (9.4/10)           â”‚   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                           â”‚
â”‚                           Data Processing Pipeline                             â”‚
â”‚                                    â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      VERIFICATION ENGINE                               â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Article         â”‚  â”‚  Credibility    â”‚  â”‚    Cross-Reference      â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Extraction      â”‚â”€â–¶â”‚  Assessment     â”‚â”€â–¶â”‚    Verification         â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚                                                                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Similarity      â”‚  â”‚  Source         â”‚  â”‚    Final Score          â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ Analysis        â”‚  â”‚  Weighting      â”‚  â”‚    Calculation          â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”— **API-Based News Sources**

### **1. GNews API**

**Coverage**: 60,000+ news websites globally  
**Strength**: Real-time news aggregation  
**Languages**: 15+ languages including English, Malay  
**Update Frequency**: Real-time

```python
class GNewsAPI:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://gnews.io/api/v4"

    def search_news(self, query, language='en', max_results=10):
        """Search for news articles"""
        params = {
            'q': query,
            'token': self.api_key,
            'lang': language,
            'max': max_results,
            'in': 'title,description',
            'sortby': 'relevance'
        }

        response = requests.get(f"{self.base_url}/search", params=params)
        return self._process_response(response.json())

    def _process_response(self, data):
        """Process API response into standardized format"""
        articles = []
        for article in data.get('articles', []):
            articles.append({
                'title': article.get('title'),
                'description': article.get('description'),
                'url': article.get('url'),
                'source': article.get('source', {}).get('name'),
                'published_at': article.get('publishedAt'),
                'image': article.get('image'),
                'credibility_score': self._calculate_source_credibility(
                    article.get('source', {}).get('name')
                )
            })
        return articles
```

**Example Response:**

```json
{
  "totalArticles": 157,
  "articles": [
    {
      "title": "WHO Updates COVID-19 Guidelines",
      "description": "World Health Organization releases new guidelines...",
      "content": "The World Health Organization announced...",
      "url": "https://www.reuters.com/health/who-updates-covid-guidelines",
      "image": "https://example.com/image.jpg",
      "publishedAt": "2025-09-20T08:00:00Z",
      "source": {
        "name": "Reuters",
        "url": "https://reuters.com"
      }
    }
  ]
}
```

### **2. NewsAPI.org**

**Coverage**: 80,000+ sources worldwide  
**Strength**: Comprehensive historical data  
**Features**: Full article content, source metadata  
**Rate Limit**: 1,000 requests/day (free), unlimited (paid)

```python
class NewsAPIOrg:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://newsapi.org/v2"

    def search_everything(self, query, language='en', sort_by='relevancy'):
        """Search all articles"""
        params = {
            'q': query,
            'apiKey': self.api_key,
            'language': language,
            'sortBy': sort_by,
            'pageSize': 20
        }

        response = requests.get(f"{self.base_url}/everything", params=params)
        return self._process_articles(response.json().get('articles', []))

    def get_top_headlines(self, category='general', country='us'):
        """Get top headlines by category/country"""
        params = {
            'apiKey': self.api_key,
            'category': category,
            'country': country,
            'pageSize': 20
        }

        response = requests.get(f"{self.base_url}/top-headlines", params=params)
        return self._process_articles(response.json().get('articles', []))
```

### **3. Currents API**

**Coverage**: 50,000+ sources in 50+ countries  
**Strength**: International coverage and breaking news  
**Categories**: Politics, Health, Science, Technology, Sports  
**Languages**: 20+ languages

### **4. Guardian API**

**Coverage**: The Guardian newspaper archives  
**Strength**: High-quality journalism and fact-checking  
**History**: Articles dating back to 1999  
**Features**: Tags, sections, contributor information

---

## ðŸ“¡ **RSS Feed Sources**

### **International News Sources**

| Source               | Credibility | URL                                         | Coverage                |
| -------------------- | ----------- | ------------------------------------------- | ----------------------- |
| **Reuters**          | 9.5/10      | `http://feeds.reuters.com/reuters/topNews`  | Global news, financial  |
| **BBC News**         | 9.2/10      | `http://feeds.bbci.co.uk/news/rss.xml`      | International, UK focus |
| **Associated Press** | 9.4/10      | `https://feeds.apnews.com/rss/apf-topnews`  | Breaking news, politics |
| **NPR**              | 8.8/10      | `https://feeds.npr.org/1001/rss.xml`        | US news, analysis       |
| **Deutsche Welle**   | 8.8/10      | `https://rss.dw.com/rdf/rss-en-all`         | European perspective    |
| **France 24**        | 8.6/10      | `https://www.france24.com/en/rss`           | International news      |
| **Al Jazeera**       | 8.7/10      | `https://www.aljazeera.com/xml/rss/all.xml` | Middle East, global     |

### **Malaysian News Sources**

| Source                    | Credibility | URL                                                | Focus                |
| ------------------------- | ----------- | -------------------------------------------------- | -------------------- |
| **Bernama**               | 9.0/10      | `https://www.bernama.com/en/rss/news_breaking.xml` | National news agency |
| **The Star**              | 8.8/10      | `https://www.thestar.com.my/rss/news/`             | General news         |
| **New Straits Times**     | 8.6/10      | `https://www.nst.com.my/rss/news`                  | Politics, business   |
| **Malay Mail**            | 8.4/10      | `https://www.malaymail.com/rss/malaysia`           | Local news           |
| **Free Malaysia Today**   | 8.2/10      | `https://www.freemalaysiatoday.com/rss/`           | Political coverage   |
| **The Malaysian Insight** | 8.3/10      | `https://www.themalaysianinsight.com/rss/`         | Analysis, opinion    |

### **Specialized Sources**

| Category       | Source           | Credibility | Focus                    |
| -------------- | ---------------- | ----------- | ------------------------ |
| **Health**     | WHO News         | 9.8/10      | Global health guidelines |
| **Science**    | Nature News      | 9.6/10      | Scientific research      |
| **Technology** | MIT Tech Review  | 9.1/10      | Technology analysis      |
| **Climate**    | IPCC Reports     | 9.7/10      | Climate science          |
| **Finance**    | Financial Times  | 9.0/10      | Economic news            |
| **Government** | Official Portals | 9.4/10      | Policy announcements     |

---

## ðŸ”„ **Data Processing Pipeline**

### **1. Parallel Source Querying**

```python
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor, as_completed

class ParallelNewsAggregator:
    def __init__(self):
        self.timeout = 10  # seconds
        self.max_workers = 10

    async def fetch_from_multiple_sources(self, query):
        """Fetch news from multiple sources in parallel"""
        sources = [
            self._fetch_gnews,
            self._fetch_newsapi,
            self._fetch_currents,
            self._fetch_rss_feeds
        ]

        async with aiohttp.ClientSession() as session:
            tasks = [source(session, query) for source in sources]
            results = await asyncio.gather(*tasks, return_exceptions=True)

        # Combine and process results
        all_articles = []
        for result in results:
            if isinstance(result, list):
                all_articles.extend(result)
            elif isinstance(result, Exception):
                logger.warning(f"Source failed: {result}")

        return self._process_articles(all_articles)

    async def _fetch_gnews(self, session, query):
        """Fetch from GNews API"""
        url = "https://gnews.io/api/v4/search"
        params = {
            'q': query,
            'token': self.gnews_api_key,
            'lang': 'en',
            'max': 10
        }

        try:
            async with session.get(url, params=params, timeout=self.timeout) as response:
                data = await response.json()
                return self._format_gnews_articles(data.get('articles', []))
        except Exception as e:
            logger.error(f"GNews fetch failed: {e}")
            return []
```

### **2. Article Relevance Scoring**

```python
from fuzzywuzzy import fuzz
import re

class RelevanceScorer:
    def __init__(self):
        self.title_weight = 0.4
        self.description_weight = 0.3
        self.content_weight = 0.3

    def calculate_relevance(self, article, query):
        """Calculate relevance score for article"""
        title_score = self._text_similarity(article.get('title', ''), query)
        desc_score = self._text_similarity(article.get('description', ''), query)
        content_score = self._text_similarity(article.get('content', ''), query)

        final_score = (
            title_score * self.title_weight +
            desc_score * self.description_weight +
            content_score * self.content_weight
        )

        return min(1.0, final_score / 100.0)  # Normalize to 0-1

    def _text_similarity(self, text, query):
        """Calculate text similarity using fuzzy matching"""
        if not text or not query:
            return 0

        # Clean text
        text = re.sub(r'[^\w\s]', '', text.lower())
        query = re.sub(r'[^\w\s]', '', query.lower())

        # Multiple similarity measures
        ratio = fuzz.ratio(query, text)
        partial_ratio = fuzz.partial_ratio(query, text)
        token_sort_ratio = fuzz.token_sort_ratio(query, text)

        return max(ratio, partial_ratio, token_sort_ratio)
```

### **3. Source Credibility Assessment**

```python
class CredibilityAssessor:
    def __init__(self):
        self.source_ratings = {
            # Tier 1: Highest credibility (9.0-10.0)
            'reuters': 9.5,
            'bbc': 9.2,
            'associated press': 9.4,
            'who': 9.8,
            'nature': 9.6,
            'bernama': 9.0,

            # Tier 2: High credibility (8.0-8.9)
            'cnn': 8.5,
            'npr': 8.8,
            'the star': 8.8,
            'new straits times': 8.6,
            'al jazeera': 8.7,

            # Tier 3: Moderate credibility (7.0-7.9)
            'buzzfeed news': 7.8,
            'vox': 7.5,
            'huffpost': 7.6,

            # Default for unknown sources
            'unknown': 6.0
        }

    def get_source_credibility(self, source_name):
        """Get credibility score for news source"""
        if not source_name:
            return self.source_ratings['unknown']

        source_clean = source_name.lower().strip()

        # Exact match
        if source_clean in self.source_ratings:
            return self.source_ratings[source_clean]

        # Partial match
        for known_source, rating in self.source_ratings.items():
            if known_source in source_clean or source_clean in known_source:
                return rating

        return self.source_ratings['unknown']

    def calculate_weighted_credibility(self, articles):
        """Calculate weighted credibility across multiple articles"""
        if not articles:
            return 0.0

        total_weight = 0
        weighted_sum = 0

        for article in articles:
            credibility = self.get_source_credibility(article.get('source', ''))
            relevance = article.get('relevance_score', 0.5)

            weight = credibility * relevance
            weighted_sum += credibility * weight
            total_weight += weight

        return weighted_sum / total_weight if total_weight > 0 else 0.0
```

---

## ðŸ” **Multi-Source Verification Process**

### **Step 1: Query Processing**

```python
class QueryProcessor:
    def __init__(self):
        self.stop_words = set(['is', 'the', 'a', 'an', 'and', 'or', 'but'])

    def extract_keywords(self, query):
        """Extract important keywords from query"""
        # Remove common words
        words = query.lower().split()
        keywords = [word for word in words if word not in self.stop_words]

        # Add variations
        expanded_keywords = keywords.copy()
        for keyword in keywords:
            # Add synonyms (simplified)
            if keyword == 'covid':
                expanded_keywords.extend(['coronavirus', 'covid-19', 'sars-cov-2'])
            elif keyword == 'vaccine':
                expanded_keywords.extend(['vaccination', 'immunization'])

        return expanded_keywords

    def generate_search_queries(self, main_query):
        """Generate multiple search variations"""
        keywords = self.extract_keywords(main_query)

        queries = [main_query]  # Original query

        # Keyword combinations
        if len(keywords) > 1:
            queries.append(' '.join(keywords[:3]))  # Top 3 keywords

        # Add specific variations
        queries.append(f'"{main_query}"')  # Exact phrase
        queries.append(' OR '.join(keywords[:2]))  # Alternative keywords

        return queries
```

### **Step 2: Cross-Source Validation**

```python
class CrossSourceValidator:
    def __init__(self):
        self.minimum_sources = 3
        self.consensus_threshold = 0.6

    def validate_claim(self, query, articles):
        """Validate claim across multiple sources"""
        if len(articles) < self.minimum_sources:
            return {
                'status': 'insufficient_sources',
                'confidence': 'low',
                'evidence_strength': 'weak'
            }

        # Analyze consensus
        supporting_articles = []
        contradicting_articles = []
        neutral_articles = []

        for article in articles:
            sentiment = self._analyze_article_stance(article, query)

            if sentiment > 0.3:
                supporting_articles.append(article)
            elif sentiment < -0.3:
                contradicting_articles.append(article)
            else:
                neutral_articles.append(article)

        total_articles = len(articles)
        support_ratio = len(supporting_articles) / total_articles
        contradict_ratio = len(contradicting_articles) / total_articles

        return self._determine_consensus(
            support_ratio, contradict_ratio, articles
        )

    def _analyze_article_stance(self, article, query):
        """Analyze if article supports or contradicts the claim"""
        # Simplified sentiment analysis
        title = article.get('title', '').lower()
        description = article.get('description', '').lower()

        positive_indicators = ['confirms', 'proves', 'shows', 'demonstrates', 'supports']
        negative_indicators = ['debunks', 'disproves', 'false', 'myth', 'incorrect']

        positive_score = sum(1 for word in positive_indicators if word in title or word in description)
        negative_score = sum(1 for word in negative_indicators if word in title or word in description)

        return (positive_score - negative_score) / max(1, positive_score + negative_score)

    def _determine_consensus(self, support_ratio, contradict_ratio, articles):
        """Determine final consensus based on source analysis"""
        if support_ratio >= self.consensus_threshold:
            return {
                'status': 'verified',
                'confidence': 'high' if support_ratio > 0.8 else 'medium',
                'evidence_strength': 'strong',
                'supporting_sources': len([a for a in articles if self._analyze_article_stance(a, '') > 0.3]),
                'total_sources': len(articles)
            }
        elif contradict_ratio >= self.consensus_threshold:
            return {
                'status': 'disputed',
                'confidence': 'high' if contradict_ratio > 0.8 else 'medium',
                'evidence_strength': 'strong',
                'contradicting_sources': len([a for a in articles if self._analyze_article_stance(a, '') < -0.3]),
                'total_sources': len(articles)
            }
        else:
            return {
                'status': 'mixed_evidence',
                'confidence': 'low',
                'evidence_strength': 'mixed',
                'supporting_sources': int(support_ratio * len(articles)),
                'contradicting_sources': int(contradict_ratio * len(articles)),
                'total_sources': len(articles)
            }
```

---

## ðŸ“Š **Source Performance Monitoring**

### **Real-time Health Monitoring**

```python
import time
from datetime import datetime, timedelta

class SourceHealthMonitor:
    def __init__(self):
        self.health_data = {}
        self.check_interval = 300  # 5 minutes

    def monitor_source_health(self, source_name, check_function):
        """Monitor individual source health"""
        start_time = time.time()

        try:
            result = check_function()
            response_time = (time.time() - start_time) * 1000  # ms

            self.health_data[source_name] = {
                'status': 'healthy',
                'response_time_ms': response_time,
                'last_check': datetime.utcnow(),
                'error_count': self.health_data.get(source_name, {}).get('error_count', 0),
                'success_rate': self._calculate_success_rate(source_name, True)
            }

            return True

        except Exception as e:
            error_count = self.health_data.get(source_name, {}).get('error_count', 0) + 1

            self.health_data[source_name] = {
                'status': 'unhealthy',
                'error': str(e),
                'last_check': datetime.utcnow(),
                'error_count': error_count,
                'success_rate': self._calculate_success_rate(source_name, False)
            }

            return False

    def get_overall_health(self):
        """Get overall system health"""
        if not self.health_data:
            return {'status': 'unknown', 'healthy_sources': 0, 'total_sources': 0}

        healthy_sources = sum(1 for data in self.health_data.values()
                            if data['status'] == 'healthy')
        total_sources = len(self.health_data)

        health_percentage = (healthy_sources / total_sources) * 100

        if health_percentage >= 80:
            status = 'healthy'
        elif health_percentage >= 60:
            status = 'degraded'
        else:
            status = 'unhealthy'

        return {
            'status': status,
            'health_percentage': health_percentage,
            'healthy_sources': healthy_sources,
            'total_sources': total_sources,
            'average_response_time': self._calculate_average_response_time()
        }
```

### **Performance Analytics**

```python
class SourceAnalytics:
    def __init__(self):
        self.performance_data = {}

    def record_request(self, source_name, response_time, success):
        """Record source request performance"""
        if source_name not in self.performance_data:
            self.performance_data[source_name] = {
                'requests': [],
                'total_requests': 0,
                'successful_requests': 0,
                'average_response_time': 0
            }

        data = self.performance_data[source_name]

        # Add request record
        data['requests'].append({
            'timestamp': datetime.utcnow(),
            'response_time': response_time,
            'success': success
        })

        # Keep only last 1000 requests
        if len(data['requests']) > 1000:
            data['requests'] = data['requests'][-1000:]

        # Update counters
        data['total_requests'] += 1
        if success:
            data['successful_requests'] += 1

        # Calculate metrics
        recent_requests = [r for r in data['requests']
                         if r['timestamp'] > datetime.utcnow() - timedelta(hours=24)]

        if recent_requests:
            data['average_response_time'] = sum(r['response_time'] for r in recent_requests) / len(recent_requests)
            data['success_rate'] = sum(1 for r in recent_requests if r['success']) / len(recent_requests)

    def get_source_analytics(self, source_name):
        """Get detailed analytics for a source"""
        if source_name not in self.performance_data:
            return None

        data = self.performance_data[source_name]
        recent_requests = [r for r in data['requests']
                         if r['timestamp'] > datetime.utcnow() - timedelta(hours=24)]

        return {
            'source_name': source_name,
            'total_requests_24h': len(recent_requests),
            'success_rate_24h': sum(1 for r in recent_requests if r['success']) / len(recent_requests) if recent_requests else 0,
            'average_response_time_24h': sum(r['response_time'] for r in recent_requests) / len(recent_requests) if recent_requests else 0,
            'requests_per_hour': len(recent_requests) / 24,
            'status': 'healthy' if data.get('success_rate', 0) > 0.8 else 'degraded'
        }
```

---

## ðŸŽ¯ **Data Verification Workflow**

### **Complete Verification Process**

```python
class ComprehensiveVerificationEngine:
    def __init__(self):
        self.news_aggregator = ParallelNewsAggregator()
        self.relevance_scorer = RelevanceScorer()
        self.credibility_assessor = CredibilityAssessor()
        self.cross_validator = CrossSourceValidator()
        self.health_monitor = SourceHealthMonitor()

    async def verify_claim(self, query):
        """Complete claim verification workflow"""
        verification_start = time.time()

        # Step 1: Gather articles from multiple sources
        articles = await self.news_aggregator.fetch_from_multiple_sources(query)

        # Step 2: Score relevance and credibility
        scored_articles = []
        for article in articles:
            relevance = self.relevance_scorer.calculate_relevance(article, query)
            credibility = self.credibility_assessor.get_source_credibility(
                article.get('source', '')
            )

            article['relevance_score'] = relevance
            article['credibility_score'] = credibility
            article['combined_score'] = relevance * credibility

            if relevance > 0.3:  # Filter irrelevant articles
                scored_articles.append(article)

        # Step 3: Sort by combined score
        scored_articles.sort(key=lambda x: x['combined_score'], reverse=True)
        top_articles = scored_articles[:20]  # Top 20 most relevant and credible

        # Step 4: Cross-source validation
        validation_result = self.cross_validator.validate_claim(query, top_articles)

        # Step 5: Calculate final credibility score
        final_credibility = self._calculate_final_credibility(
            top_articles, validation_result
        )

        processing_time = (time.time() - verification_start) * 1000

        return {
            'query': query,
            'articles_found': len(articles),
            'relevant_articles': len(top_articles),
            'verification_result': validation_result,
            'credibility_score': final_credibility,
            'top_sources': [
                {
                    'title': article['title'],
                    'source': article['source'],
                    'credibility': article['credibility_score'],
                    'relevance': article['relevance_score'],
                    'url': article['url']
                }
                for article in top_articles[:5]
            ],
            'processing_time_ms': processing_time,
            'timestamp': datetime.utcnow().isoformat()
        }

    def _calculate_final_credibility(self, articles, validation_result):
        """Calculate final credibility score (0-10)"""
        if not articles:
            return 0.0

        # Base score from source credibility
        avg_credibility = sum(a['credibility_score'] for a in articles) / len(articles)

        # Adjust based on consensus
        consensus_multiplier = {
            'verified': 1.2,
            'disputed': 0.3,
            'mixed_evidence': 0.6,
            'insufficient_sources': 0.4
        }.get(validation_result['status'], 0.5)

        # Confidence adjustment
        confidence_multiplier = {
            'high': 1.0,
            'medium': 0.8,
            'low': 0.6
        }.get(validation_result['confidence'], 0.5)

        final_score = avg_credibility * consensus_multiplier * confidence_multiplier

        return min(10.0, max(0.0, final_score))
```

---

## ðŸ“ˆ **Source Coverage Statistics**

### **Global Coverage**

- **Total Sources**: 100+
- **Countries Covered**: 50+
- **Languages Supported**: 25+
- **Update Frequency**: Real-time to hourly
- **Article Volume**: 500,000+ articles/day

### **Source Distribution**

```python
SOURCE_STATISTICS = {
    'by_region': {
        'North America': 35,
        'Europe': 25,
        'Asia Pacific': 20,
        'Malaysia': 15,
        'Others': 5
    },
    'by_type': {
        'News Agencies': 25,
        'Newspapers': 30,
        'Broadcasters': 20,
        'Digital Native': 15,
        'Government/Official': 10
    },
    'by_credibility': {
        '9.0-10.0 (Highest)': 20,
        '8.0-8.9 (High)': 40,
        '7.0-7.9 (Good)': 25,
        '6.0-6.9 (Moderate)': 15
    }
}
```

---

This comprehensive documentation demonstrates how Trustify AI leverages an extensive network of trusted news sources to provide accurate, multi-source verification of claims. The system's strength lies in its ability to cross-reference information across diverse, credible sources while maintaining high performance and reliability.

**Key Data Integration Strengths:**

- âœ… **Comprehensive Coverage**: 100+ sources across 50+ countries
- âœ… **Real-time Processing**: Parallel querying for fast results
- âœ… **Quality Control**: Credibility scoring and source verification
- âœ… **Multi-language Support**: 25+ languages including Malay
- âœ… **Performance Monitoring**: Real-time health tracking
- âœ… **Cross-validation**: Multiple source consensus analysis
